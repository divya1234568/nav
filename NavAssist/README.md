# ğŸ§­ NavAssist â€” Smart Navigation App for Disabled Persons

A complete Android app with:
- ğŸ“¸ **Real-time AI camera** object detection (ML Kit â€” works offline!)
- ğŸ”Š **Text-to-Speech** voice guidance for blind users
- ğŸ¤ **Voice commands** recognition
- ğŸ“³ **Haptic vibration** alerts for deaf users
- âš¡ **Flash screen alerts** for deaf users
- ğŸ†˜ **SOS Emergency** â€” sends SMS + live location to guardians
- ğŸ›¡ï¸ **Guardian App** â€” real-time monitoring dashboard
- ğŸ”¥ **Firebase** push notifications for SOS alerts

---

## ğŸ“± BUILD THE APK (3 Steps)

### Option A â€” Easiest (Android Studio)
1. Download & install **Android Studio**: https://developer.android.com/studio
2. Open Android Studio â†’ `Open Project` â†’ select this `NavAssist` folder
3. Wait for Gradle sync (~2 minutes first time)
4. Click **â–¶ Run** button or go to `Build â†’ Build APK(s)`
5. APK appears at `app/build/outputs/apk/debug/app-debug.apk`

### Option B â€” Command Line (Linux/Mac)
```bash
chmod +x build-apk.sh
./build-apk.sh
```

### Option C â€” Command Line (Windows)
```cmd
gradlew.bat assembleDebug
```
APK: `app\build\outputs\apk\debug\app-debug.apk`

---

## âš™ï¸ BEFORE BUILDING â€” Configuration

### 1. Add Firebase (for SOS push notifications)
1. Go to https://console.firebase.google.com
2. Create project `NavAssist`
3. Add Android app with package `com.navassist`
4. Download `google-services.json`
5. Place it in `app/google-services.json`

### 2. Add Guardian Phone Numbers (for SMS SOS)
Open `app/src/main/java/com/navassist/SOSActivity.java`:
```java
private static final String[] GUARDIAN_NUMBERS = {
    "+91XXXXXXXXXX",  // â† Replace with real numbers
    "+91XXXXXXXXXX"
};
```

### 3. Add Google Maps API Key (for map in Guardian app)
In `app/src/main/AndroidManifest.xml`, add inside `<application>`:
```xml
<meta-data
    android:name="com.google.android.geo.API_KEY"
    android:value="YOUR_GOOGLE_MAPS_API_KEY"/>
```
Get key: https://console.cloud.google.com â†’ Maps SDK for Android

---

## ğŸ“² INSTALL ON PHONE

### Via USB (Developer mode):
```bash
adb install app/build/outputs/apk/debug/app-debug.apk
```

### Manually:
1. Copy `app-debug.apk` to phone
2. Settings â†’ Security â†’ **Install Unknown Apps** â†’ ON
3. Open file manager â†’ tap APK â†’ Install

---

## ğŸ—ï¸ PROJECT STRUCTURE

```
NavAssist/
â”œâ”€â”€ app/src/main/
â”‚   â”œâ”€â”€ java/com/navassist/
â”‚   â”‚   â”œâ”€â”€ SplashActivity.java       â† Mode selection screen
â”‚   â”‚   â”œâ”€â”€ MainActivity.java         â† Main hub (voice, navigate)
â”‚   â”‚   â”œâ”€â”€ CameraActivity.java       â† ğŸ”‘ Real-time AI camera
â”‚   â”‚   â”œâ”€â”€ DetectionOverlayView.java â† Bounding box drawing
â”‚   â”‚   â”œâ”€â”€ SOSActivity.java          â† Emergency SOS + SMS
â”‚   â”‚   â”œâ”€â”€ GuardianActivity.java     â† Guardian monitoring
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ NavAssistFirebaseService.java  â† Push notifications
â”‚   â”‚       â””â”€â”€ LocationTrackingService.java   â† Background GPS
â”‚   â”œâ”€â”€ res/layout/
â”‚   â”‚   â”œâ”€â”€ activity_splash.xml       â† Mode selection UI
â”‚   â”‚   â”œâ”€â”€ activity_main.xml         â† Main screen UI
â”‚   â”‚   â”œâ”€â”€ activity_camera.xml       â† Camera + detection UI
â”‚   â”‚   â”œâ”€â”€ activity_sos.xml          â† SOS screen UI
â”‚   â”‚   â”œâ”€â”€ activity_guardian.xml     â† Guardian dashboard UI
â”‚   â”‚   â””â”€â”€ item_activity.xml         â† Activity log item
â”‚   â””â”€â”€ AndroidManifest.xml
â”œâ”€â”€ build.gradle
â”œâ”€â”€ build-apk.sh                      â† One-command builder
â””â”€â”€ README.md
```

---

## ğŸ”¬ HOW AI CAMERA WORKS

The camera uses **Google ML Kit** (100% offline, on-device):

| Feature | ML Kit API | What it does |
|---------|-----------|--------------|
| Object Detection | `ObjectDetection` | Detects chairs, doors, people, products with bounding boxes |
| Image Labeling | `ImageLabeling` | Identifies scenes: store, hospital, outdoor, food |
| Text Recognition | `TextRecognition` | Reads signs, menus, product labels, notices |

All 3 run on-device â€” **no internet needed** for camera AI.

---

## ğŸ†˜ SOS FLOW

```
User presses SOS
       â†“
Location captured (GPS)
       â†“
SMS sent to guardian numbers (with Google Maps link)
       â†“
Firebase push notification â†’ Guardian's phone
       â†“
Guardian app shows alert banner + vibrates + sound
```

---

## ğŸ“‹ PERMISSIONS REQUIRED

| Permission | Why |
|-----------|-----|
| CAMERA | Real-time object detection |
| ACCESS_FINE_LOCATION | Live GPS for SOS + navigation |
| RECORD_AUDIO | Voice commands |
| SEND_SMS | SOS alerts to guardians |
| VIBRATE | Haptic feedback for deaf users |
| CALL_PHONE | Emergency call from guardian |
| POST_NOTIFICATIONS | SOS push alerts |

---

## ğŸ› ï¸ TECH STACK

- **Language**: Java (Android)
- **Min SDK**: Android 7.0 (API 24)
- **Camera**: CameraX 1.3.1
- **AI**: Google ML Kit (Object Detection + Image Labeling + OCR)
- **Location**: Google Play Services Location
- **Notifications**: Firebase Cloud Messaging (FCM)
- **Database**: Firebase Realtime Database
- **TTS**: Android Built-in TextToSpeech
- **Voice**: Android SpeechRecognizer
